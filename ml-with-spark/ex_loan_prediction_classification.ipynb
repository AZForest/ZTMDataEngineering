{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "039b794b-7333-4793-816e-7d6c65e776ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession \\\n",
    "  .builder \\\n",
    "  .appName(\"Exercise for loan prediction classification\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "010c5ef4-3002-44f3-a96b-daf43317bf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Loan_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Married: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Self_Employed: string (nullable = true)\n",
      " |-- ApplicantIncome: integer (nullable = true)\n",
      " |-- CoapplicantIncome: double (nullable = true)\n",
      " |-- LoanAmount: integer (nullable = true)\n",
      " |-- Loan_Amount_Term: integer (nullable = true)\n",
      " |-- Credit_History: integer (nullable = true)\n",
      " |-- Property_Area: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"data/loan_prediction_problem_dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "750bfc8d-661c-492b-970e-ed279d0c27ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "|Loan_ID|Gender|Married|Dependents|Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
      "+-------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "|    614|   601|    611|       599|      614|          582|            614|              614|       592|             600|           564|          614|        614|\n",
      "+-------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data \\\n",
    "    .select([F.count(F.when(F.col(c).isNotNull(), 1)).alias(c) for c in data.columns]) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ebfc24a1-0690-4271-b0d0-3b8a6006c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6721c33d-959a-4b72-877d-a28d8ea6b7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "|Loan_ID|Gender|Married|Dependents|Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
      "+-------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "|    480|   480|    480|       480|      480|          480|            480|              480|       480|             480|           480|          480|        480|\n",
      "+-------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df \\\n",
    "    .select([F.count(F.when(F.col(c).isNotNull(), 1)).alias(c) for c in data.columns]) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "6fa0c067-e659-4c53-a925-09d9c11feef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Loan_Status|\n",
      "+-----------+\n",
      "|          N|\n",
      "|          Y|\n",
      "|          Y|\n",
      "|          Y|\n",
      "|          Y|\n",
      "|          Y|\n",
      "|          N|\n",
      "|          Y|\n",
      "|          N|\n",
      "|          Y|\n",
      "|          Y|\n",
      "|          N|\n",
      "|          Y|\n",
      "|          Y|\n",
      "|          N|\n",
      "|          N|\n",
      "|          N|\n",
      "|          Y|\n",
      "|          N|\n",
      "|          Y|\n",
      "+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "clean_df.select(\"Loan_Status\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f85b7e22-1fd2-405e-969d-dc163c6834c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  409\n",
      "Test size:  71\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = clean_df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(\"Train size: \", train_data.count())\n",
    "print(\"Test size: \", test_data.count())                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "18b2e70b-2e41-477c-b780-b134eafdaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7a81c5c4-df7e-4ad4-ae76-990b93328609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Loan_ID',\n",
       " 'Gender',\n",
       " 'Married',\n",
       " 'Dependents',\n",
       " 'Education',\n",
       " 'Self_Employed',\n",
       " 'Property_Area',\n",
       " 'Loan_Status']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "stringCols = []\n",
    "for column in train_data.columns:\n",
    "    if isinstance(train_data.schema[column].dataType, StringType):\n",
    "        # print(f\"Column '{column}' is of type string.\")\n",
    "        stringCols.append(column)\n",
    "stringCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "03e345b7-31e2-4b83-a530-394a7e47b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "for column in stringCols:\n",
    "    indexer = StringIndexer(inputCol=column, outputCol=f'{column}_index')\n",
    "    indexer_model = indexer.fit(train_data)\n",
    "    train_data = indexer_model.transform(train_data)\n",
    "    # test_data = indexer_model.transform(test_data)\n",
    "\n",
    "# indexer = StringIndexer(inputCol='ocean_proximity', outputCol='ocean_proximity_index')\n",
    "# indexer_model = indexer.fit(train_data)\n",
    "# train_data = indexer_model.transform(train_data)\n",
    "# train_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "78fa7edc-79da-4a44-864d-df1a46a7d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b0aaba9d-06b6-4d4e-9722-d7c35731bb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|Loan_Status|Loan_Status_index|\n",
      "+-----------+-----------------+\n",
      "|          N|              1.0|\n",
      "|          Y|              0.0|\n",
      "|          Y|              0.0|\n",
      "|          Y|              0.0|\n",
      "|          Y|              0.0|\n",
      "|          Y|              0.0|\n",
      "|          Y|              0.0|\n",
      "|          Y|              0.0|\n",
      "|          N|              1.0|\n",
      "|          Y|              0.0|\n",
      "|          N|              1.0|\n",
      "|          N|              1.0|\n",
      "|          N|              1.0|\n",
      "|          Y|              0.0|\n",
      "|          N|              1.0|\n",
      "|          Y|              0.0|\n",
      "|          Y|              0.0|\n",
      "|          N|              1.0|\n",
      "|          N|              1.0|\n",
      "|          Y|              0.0|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "train_data.select(\"Loan_Status\", \"Loan_Status_index\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6e77d43d-e052-4937-bcac-89ed0eb9ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.show(5)\n",
    "stringCols.remove('Loan_Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "15d875ba-ec56-496d-ab7e-27997ffbd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "for column in stringCols:\n",
    "    encoder = OneHotEncoder(inputCol=f'{column}_index', outputCol=f'{column}_vec', dropLast=False)\n",
    "    encoder_model = encoder.fit(train_data)\n",
    "    train_data = encoder_model.transform(train_data)\n",
    "    # test_data = encoder_model.transform(test_data)\n",
    "\n",
    "# encoder = OneHotEncoder(inputCol='ocean_proximity_index', outputCol='ocean_proximity_vec', dropLast=False)\n",
    "# encoder_model = encoder.fit(train_data)\n",
    "# train_data = encoder_model.transform(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9299d3b9-ac58-405c-b02a-d9cf3602029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ba9fa7cb-dc60-4b44-aaca-1ffebfd7dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplicantIncome',\n",
       " 'CoapplicantIncome',\n",
       " 'LoanAmount',\n",
       " 'Loan_Amount_Term',\n",
       " 'Credit_History',\n",
       " 'Loan_ID_vec',\n",
       " 'Gender_vec',\n",
       " 'Married_vec',\n",
       " 'Dependents_vec',\n",
       " 'Education_vec',\n",
       " 'Self_Employed_vec',\n",
       " 'Property_Area_vec']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_for_assembler = []\n",
    "for column in train_data.columns:\n",
    "    # print(f'{column} -> {(train_data.schema[column].dataType)}')\n",
    "    if not isinstance(train_data.schema[column].dataType, StringType) and \\\n",
    "    \"_index\" not in column:\n",
    "        columns_for_assembler.append(column)\n",
    "columns_for_assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4bbbacee-86db-4b60-aa08-19f65bdcba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in train_data.columns:\n",
    "#     print(f'{column} -> {(train_data.schema[column].dataType)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3d70f6be-f22e-464a-81b9-38eeabf4eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=columns_for_assembler, outputCol='unscaled_features')\n",
    "\n",
    "train_data = assembler.transform(train_data)\n",
    "# test_data = assembler.transform(test_data)\n",
    "# train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c841ad-4f61-441c-9a32-a0af2cad1b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2414f0c9-adb3-4f0a-bcb1-b7153df34c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol='unscaled_features', outputCol='features', withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(train_data)\n",
    "transformed_train_data = scaler_model.transform(train_data)\n",
    "# test_data = scaler_model.transform(test_data)\n",
    "# transformed_train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e8ada4d3-f596-4282-9a1d-645f98403df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/02 18:40:53 WARN Instrumentation: [4ac74b0a] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/09/02 18:40:53 WARN Instrumentation: [4ac74b0a] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='Loan_Status_index')\n",
    "\n",
    "model = lr.fit(transformed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8e87b688-3320-466b-a61c-996db0d2d568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "| Loan_ID|Gender|Married|Dependents|   Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
      "+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "|LP001006|  Male|    Yes|         0|Not Graduate|           No|           2583|           2358.0|       120|             360|             1|        Urban|          Y|\n",
      "|LP001014|  Male|    Yes|        3+|    Graduate|           No|           3036|           2504.0|       158|             360|             0|    Semiurban|          N|\n",
      "|LP001020|  Male|    Yes|         1|    Graduate|           No|          12841|          10968.0|       349|             360|             1|    Semiurban|          N|\n",
      "|LP001032|  Male|     No|         0|    Graduate|           No|           4950|              0.0|       125|             360|             1|        Urban|          Y|\n",
      "|LP001066|  Male|    Yes|         0|    Graduate|          Yes|           9560|              0.0|       191|             360|             1|    Semiurban|          Y|\n",
      "+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "75ec9680-278d-4a84-928b-c424f3551125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = indexer_model.transform(test_data)\n",
    "# test_data = encoder_model.transform(test_data)\n",
    "# test_data = assembler.transform(test_data)\n",
    "# test_data = scaler_model.transform(test_data)\n",
    "# test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d5f77bfe-7e57-4e4c-8e79-54a06324b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = model.transform(test_data)\n",
    "# test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8cb1b-f252-4b84-8293-a39423c77a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
